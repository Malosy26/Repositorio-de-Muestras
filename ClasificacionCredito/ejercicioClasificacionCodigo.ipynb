{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0117658-7c62-4591-a65f-901634309067",
   "metadata": {
    "tags": []
   },
   "source": [
    "En el siguiente ejercicio se presenta un set de datos con el que trataremos de clasificar si un cliente es solvente o no a la hora de devolver un crédito solicitado a una entidad bancaria.\n",
    "\n",
    "Para ponernos en situación pertenecemos al equipo de Data Science de una entidad bancaria y se no pide realizar un modelo que sea capaz de evaluar el riesgo de un cliente cuando nos solicita un crédito a través de una tarjeta de crédito en base al histórico de datos que os pasan desde el equipo de negocio (datos extraidos de kaggle).\n",
    "\n",
    "A continuación os dejan una breve explicación de en que consiste cada una de las variables del conjunto de datos:\n",
    "\n",
    "- BAD: 1 = candidato con préstamo incumplido o con mora; 0 = candidato que paga su deuda y no tiene registro negativo\n",
    "- LOAN: Cantidad de solicitud de préstamo\n",
    "- MORTDUE: Cantidad adeudada de la hipoteca existente\n",
    "- VALUE: Valor actual del bien o propiedad\n",
    "- REASON: DebtCon = consolidación de la deuda; HomeImp = mejoras para el hogar\n",
    "- JOB: Categorias ocupacionales o profesionales\n",
    "- YOJ: Años es esu trabajo actual\n",
    "- DEROG: Número de informes derogados o cancelados importantes\n",
    "- DELINQ: Número de lineas de crédito morosas\n",
    "- CLAGE: Antiguedad de la linea de crédito más antigua en meses\n",
    "- NINQ:Número de consultas crediticas recientes\n",
    "- CLNO: Número de líneas de crédito\n",
    "\n",
    "En este caso la target de nuestro modelo será **BAD**, el resto las consideraremos variables predictoras.\n",
    "\n",
    "Que se espera que hagais:\n",
    "\n",
    "- Análisis descriptivo de los datos (esto ayudará a realizar una mejor elección del modelo a usar)\n",
    "- Tratamiento y limpieza de los datos\n",
    "- Prueba y evaluación de diferentes modelos\n",
    "- Breve explicación de los resultados, justificando la elección final del modelo (no me vale con que es el que mejor métrica tenía)\n",
    "- Que disfruteis del ejercico :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad9e44d-bea0-4f53-8da8-5cb3daffbe57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import LibreriasClasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807289a0-4152-421b-80fb-9135f7c48af7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>JOB</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1100</td>\n",
       "      <td>25860.0</td>\n",
       "      <td>39025.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.366667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1300</td>\n",
       "      <td>70053.0</td>\n",
       "      <td>68400.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>16700.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.466667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1700</td>\n",
       "      <td>97800.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Office</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BAD  LOAN  MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \\\n",
       "0    1  1100  25860.0   39025.0  HomeImp   Other  10.5    0.0     0.0   \n",
       "1    1  1300  70053.0   68400.0  HomeImp   Other   7.0    0.0     2.0   \n",
       "2    1  1500  13500.0   16700.0  HomeImp   Other   4.0    0.0     0.0   \n",
       "3    1  1500      NaN       NaN      NaN     NaN   NaN    NaN     NaN   \n",
       "4    0  1700  97800.0  112000.0  HomeImp  Office   3.0    0.0     0.0   \n",
       "\n",
       "        CLAGE  NINQ  CLNO  DEBTINC  \n",
       "0   94.366667   1.0   9.0      NaN  \n",
       "1  121.833333   0.0  14.0      NaN  \n",
       "2  149.466667   1.0  10.0      NaN  \n",
       "3         NaN   NaN   NaN      NaN  \n",
       "4   93.333333   0.0  14.0      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1 = pd.read_csv(r'D:\\bootcamp\\dsb06rt\\mod5-machine-learning-y-deep-learning\\29_11_2023\\credit_risk.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538baf0-34b5-4037-b8ac-4958489c3fa2",
   "metadata": {},
   "source": [
    "TRATAMIENTO DE LOS DATOS PARA VER QUE METODO TIENE MAS PRECISIO SIN NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f38635-26d8-4a76-a5f8-8599cfadae50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_no_nan=df1.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2e0a4b-f120-4f0d-9b6a-5609e79a0e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3364 entries, 5 to 5959\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   BAD      3364 non-null   int64  \n",
      " 1   LOAN     3364 non-null   int64  \n",
      " 2   MORTDUE  3364 non-null   float64\n",
      " 3   VALUE    3364 non-null   float64\n",
      " 4   REASON   3364 non-null   object \n",
      " 5   JOB      3364 non-null   object \n",
      " 6   YOJ      3364 non-null   float64\n",
      " 7   DEROG    3364 non-null   float64\n",
      " 8   DELINQ   3364 non-null   float64\n",
      " 9   CLAGE    3364 non-null   float64\n",
      " 10  NINQ     3364 non-null   float64\n",
      " 11  CLNO     3364 non-null   float64\n",
      " 12  DEBTINC  3364 non-null   float64\n",
      "dtypes: float64(9), int64(2), object(2)\n",
      "memory usage: 367.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_no_nan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ceb1f8-20df-4081-bace-26c6f23218c2",
   "metadata": {},
   "source": [
    "Tratamos las categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8e6ab9-8316-4481-8f49-6ed5e6c715e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebtCon    2369\n",
       "HomeImp     995\n",
       "Name: REASON, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_nan.REASON.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa06c3f-f998-4f80-92ac-3d6d7fb16852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other      1286\n",
       "ProfExe     899\n",
       "Office      577\n",
       "Mgr         450\n",
       "Self         99\n",
       "Sales        53\n",
       "Name: JOB, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_nan.JOB.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a72d675-6496-4056-afea-71818f7b0010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dic_re={'DebtCon':1,'HomeImp':2}\n",
    "dic_job={'Other':1,'ProfExe':2,'Office':3,'Mgr':4,'Self':5,'Sales':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd22091f-733f-473b-8004-72e522635a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_no_nan['JobEnum']=df_no_nan['JOB'].map(dic_job)\n",
    "df_no_nan['ReasonEnum']=df_no_nan['REASON'].map(dic_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8727cb3d-f5fa-40cd-9826-5c9f38852ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>JOB</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "      <th>JobEnum</th>\n",
       "      <th>ReasonEnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1700</td>\n",
       "      <td>30548.0</td>\n",
       "      <td>40320.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.466002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.113614</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>28502.0</td>\n",
       "      <td>43034.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Other</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.766030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.884894</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>2300</td>\n",
       "      <td>102370.0</td>\n",
       "      <td>120953.0</td>\n",
       "      <td>HomeImp</td>\n",
       "      <td>Office</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.992533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.588503</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BAD  LOAN   MORTDUE     VALUE   REASON     JOB   YOJ  DEROG  DELINQ  \\\n",
       "5     1  1700   30548.0   40320.0  HomeImp   Other   9.0    0.0     0.0   \n",
       "7     1  1800   28502.0   43034.0  HomeImp   Other  11.0    0.0     0.0   \n",
       "19    0  2300  102370.0  120953.0  HomeImp  Office   2.0    0.0     0.0   \n",
       "\n",
       "         CLAGE  NINQ  CLNO    DEBTINC  JobEnum  ReasonEnum  \n",
       "5   101.466002   1.0   8.0  37.113614        1           2  \n",
       "7    88.766030   0.0   8.0  36.884894        1           2  \n",
       "19   90.992533   0.0  13.0  31.588503        3           2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_nan.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ca5ef-09d7-4992-92f0-743b5e799a78",
   "metadata": {},
   "source": [
    "Funcion para realizar modelos con diferentes configuraciones de momento todos los modelos se llamaran con sus ajustes por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd5b803-7c54-4adb-8ae9-cf1687d3c1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X e y ya deben estar tratadas si tienes que aplicar a y train por separado alguna modificacion \n",
    "#tienes que crear otra funcion \n",
    "#1 BOOLEANO es para saber si quieres normalizar en base a X_train\n",
    "#2 Booleano es para saber si quieres  hacer xtrain stratify=y\n",
    "def VecinosKneighbors(X,y,normalizar,stratify):\n",
    "    if(normalizar)and(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = KNeighborsClassifier(n_neighbors = 3)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "#         confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "     \n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#         plt.xlabel('Predicción')\n",
    "#         plt.ylabel('Verdad');\n",
    "#         plt.title(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "    elif(normalizar)and not(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = KNeighborsClassifier(n_neighbors = 3)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "    elif(stratify)and not(normalizar):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        model = KNeighborsClassifier(n_neighbors = 3)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "    else:\n",
    "         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "         model = KNeighborsClassifier(n_neighbors = 3)\n",
    "         model.fit(X_train, y_train)\n",
    "         yhat = model.predict(X_test)\n",
    "         print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "         print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "         print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "#          confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "#          plt.figure(figsize=(10,10))\n",
    "#          sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#          plt.xlabel('Predicción')\n",
    "#          plt.ylabel('Verdad');\n",
    "#          plt.title(f'MODELO SIN NORMALIZADO Y SIN STRATIFY EN Y')\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "#COMENTO LA FUNCION ENTERA HASTA ENTENDERLA MEJOR    \n",
    "# def VecinosRadiusNeighbors(X,y,normalizar,stratify):\n",
    "#     if(normalizar)and(stratify):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "#         scaler = MinMaxScaler()\n",
    "#         scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "#         X_train_scaler = scaler.transform(X_train)\n",
    "#         X_test_scaler = scaler.transform(X_test)\n",
    "#         model = RadiusNeighborsClassifier(radius = 0.5)\n",
    "#         model.fit(X_train_scaler, y_train)\n",
    "#         yhat = model.predict(X_test)\n",
    "#         print(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "#         print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "#         print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "# #         confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "     \n",
    "# #         plt.figure(figsize=(10,10))\n",
    "# #         sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "# #         plt.xlabel('Predicción')\n",
    "# #         plt.ylabel('Verdad');\n",
    "# #         plt.title(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "#     elif(normalizar)and not(stratify):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "#         scaler = MinMaxScaler()\n",
    "#         scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "#         X_train_scaler = scaler.transform(X_train)\n",
    "#         X_test_scaler = scaler.transform(X_test)\n",
    "#         model = RadiusNeighborsClassifier(radius = 0.5)\n",
    "#         model.fit(X_train_scaler, y_train)\n",
    "#         yhat = model.predict(X_test)\n",
    "#         print(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "#         print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "#         print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "#         # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "#         # plt.figure(figsize=(10,10))\n",
    "#         # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#         # plt.xlabel('Predicción')\n",
    "#         # plt.ylabel('Verdad');\n",
    "#         # plt.title(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "#     elif(stratify)and not(normalizar):\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "#         model = RadiusNeighborsClassifier(radius = 0.5)\n",
    "#         model.fit(X_train_scaler, y_train)\n",
    "#         yhat = model.predict(X_test)\n",
    "#         print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "#         print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "#         print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "#         print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "#         # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "#         # plt.figure(figsize=(10,10))\n",
    "#         # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#         # plt.xlabel('Predicción')\n",
    "#         # plt.ylabel('Verdad');\n",
    "#         # plt.title(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "#     else:\n",
    "#          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "#          model = RadiusNeighborsClassifier(radius = 0.5)\n",
    "#          model.fit(X_train_scaler, y_train)\n",
    "#          yhat = model.predict(X_test)\n",
    "#          print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "#          print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "#          print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "#          print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "#          print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "#          print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "         \n",
    "# #          confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "# #          plt.figure(figsize=(10,10))\n",
    "# #          sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "# #          plt.xlabel('Predicción')\n",
    "# #          plt.ylabel('Verdad');\n",
    "# #          plt.title(f'MODELO SIN NORMALIZADO Y SIN STRATIFY EN Y')\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def LogisticRegresion(X,y,normalizar,stratify):\n",
    "    if(normalizar)and(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "#         confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "     \n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#         plt.xlabel('Predicción')\n",
    "#         plt.ylabel('Verdad');\n",
    "#         plt.title(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "    elif(normalizar)and not(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "    elif(stratify)and not(normalizar):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "    else:\n",
    "         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "         model = LogisticRegression()\n",
    "         model.fit(X_train, y_train)\n",
    "         yhat = model.predict(X_test)\n",
    "         print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "         print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "         print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        \n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "def nearestCentroid(X,y,normalizar,stratify):\n",
    "    if(normalizar)and(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = NearestCentroid()\n",
    "        model.fit(X_train, y_train)  \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "#         confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "     \n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#         plt.xlabel('Predicción')\n",
    "#         plt.ylabel('Verdad');\n",
    "#         plt.title(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "    elif(normalizar)and not(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = NearestCentroid()\n",
    "        model.fit(X_train, y_train)  \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "    elif(stratify)and not(normalizar):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        model = NearestCentroid()\n",
    "        model.fit(X_train, y_train)  \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    " \n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "    else:\n",
    "         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "         model = NearestCentroid()\n",
    "         model.fit(X_train, y_train)  \n",
    "         yhat = model.predict(X_test)\n",
    "         print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "         print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "         print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "    \n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "def ArbolDecision(X,y,normalizar,stratify,min_samples):\n",
    "    if(normalizar)and(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=min_samples)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "#         confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "     \n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#         plt.xlabel('Predicción')\n",
    "#         plt.ylabel('Verdad');\n",
    "#         plt.title(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "    elif(normalizar)and not(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=min_samples)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "    elif(stratify)and not(normalizar):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=min_samples)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "    else:\n",
    "         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "         model = DecisionTreeClassifier(min_samples_leaf=min_samples)\n",
    "         model.fit(X_train, y_train) \n",
    "         yhat = model.predict(X_test)\n",
    "         print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "         print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "         print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"ROC AUC:\", roc_auc_score(y_test, yhat))    \n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    \n",
    "def ArbolRandom(X,y,normalizar,stratify):\n",
    "    if(normalizar)and(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "#         confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "     \n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#         plt.xlabel('Predicción')\n",
    "#         plt.ylabel('Verdad');\n",
    "#         plt.title(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "    elif(normalizar)and not(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "    elif(stratify)and not(normalizar):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "    else:\n",
    "         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "         model = RandomForestClassifier()\n",
    "         model.fit(X_train, y_train) \n",
    "         yhat = model.predict(X_test)\n",
    "         print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "         print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "         print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "         print(\"ROC AUC:\", roc_auc_score(y_test, yhat))        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea678ab-8003-4f25-b7ba-4807c4dcaab2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Comparativa de formas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77ad945e-2a07-47e2-9555-301847e65ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=df_no_nan.drop(['BAD','JOB','REASON'],axis=1)\n",
    "y=df_no_nan['BAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b980d00-dc91-438f-9ce5-ebf4be3f453d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.5153405902816743\n",
      "Exactitud: 0.912332838038633\n",
      "Precisión: 0.7271529888551165\n",
      "Sensibilidad: 0.5609570418705818\n",
      "F1-score: 0.5834565958562812\n",
      "ROC AUC: 0.5609570418705818\n",
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO SIN STRATIFY EN Y\n",
      "Jaccard Index: 0.5326710066070734\n",
      "Exactitud: 0.9212481426448736\n",
      "Precisión: 0.7642857142857142\n",
      "Sensibilidad: 0.5754949062282936\n",
      "F1-score: 0.6059762496547915\n",
      "ROC AUC: 0.5754949062282937\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.5153405902816743\n",
      "Exactitud: 0.912332838038633\n",
      "Precisión: 0.7271529888551165\n",
      "Sensibilidad: 0.5609570418705818\n",
      "F1-score: 0.5834565958562812\n",
      "ROC AUC: 0.5609570418705818\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.5326710066070734\n",
      "Exactitud: 0.9212481426448736\n",
      "Precisión: 0.7642857142857142\n",
      "Sensibilidad: 0.5754949062282936\n",
      "F1-score: 0.6059762496547915\n",
      "ROC AUC: 0.5754949062282937\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------')\n",
    "VecinosKneighbors(X,y,1,1)\n",
    "print('------------------------------------------------------------------')\n",
    "VecinosKneighbors(X,y,1,0)\n",
    "print('------------------------------------------------------------------')\n",
    "VecinosKneighbors(X,y,0,1)\n",
    "print('------------------------------------------------------------------')\n",
    "VecinosKneighbors(X,y,0,0)\n",
    "print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02190d55-30b8-49b7-afdf-8240b85d5b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087fece-8a73-497c-bcdd-ca4b5d2f4adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('------------------------------------------------------------------')\n",
    "# VecinosRadiusNeighbors(X,y,1,1)\n",
    "# print('------------------------------------------------------------------')\n",
    "# VecinosRadiusNeighbors(X,y,1,0)\n",
    "# print('------------------------------------------------------------------')\n",
    "# VecinosRadiusNeighbors(X,y,0,1)\n",
    "# print('------------------------------------------------------------------')\n",
    "# VecinosRadiusNeighbors(X,y,0,0)\n",
    "# print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4bf6e0e-c8b3-4305-9692-f9e74595e9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=df_no_nan.drop(['BAD','JOB','REASON'],axis=1)\n",
    "y=df_no_nan['BAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "605affea-5f46-4807-849d-5bc514380c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.4554234769687964\n",
      "Exactitud: 0.9108469539375929\n",
      "Precisión: 0.4554234769687964\n",
      "Sensibilidad: 0.5\n",
      "F1-score: 0.4766718506998445\n",
      "ROC AUC: 0.5\n",
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO SIN STRATIFY EN Y\n",
      "Jaccard Index: 0.45839524517087665\n",
      "Exactitud: 0.9167904903417533\n",
      "Precisión: 0.45839524517087665\n",
      "Sensibilidad: 0.5\n",
      "F1-score: 0.4782945736434109\n",
      "ROC AUC: 0.5\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.4554234769687964\n",
      "Exactitud: 0.9108469539375929\n",
      "Precisión: 0.4554234769687964\n",
      "Sensibilidad: 0.5\n",
      "F1-score: 0.4766718506998445\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "ROC AUC: 0.5\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.45839524517087665\n",
      "Exactitud: 0.9167904903417533\n",
      "Precisión: 0.45839524517087665\n",
      "Sensibilidad: 0.5\n",
      "F1-score: 0.4782945736434109\n",
      "ROC AUC: 0.5\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------')\n",
    "LogisticRegresion(X,y,1,1)\n",
    "print('------------------------------------------------------------------')\n",
    "LogisticRegresion(X,y,1,0)\n",
    "print('------------------------------------------------------------------')\n",
    "LogisticRegresion(X,y,0,1)\n",
    "print('------------------------------------------------------------------')\n",
    "LogisticRegresion(X,y,0,0)\n",
    "print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e62ff281-1f6b-4c2d-a203-bb7e5512f1b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=df_no_nan.drop(['BAD','JOB','REASON'],axis=1)\n",
    "y=df_no_nan['BAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f68afb12-0ddd-43c0-86a4-5d70d7b89faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.22487618911889407\n",
      "Exactitud: 0.399702823179792\n",
      "Precisión: 0.50175983436853\n",
      "Sensibilidad: 0.5050842849374659\n",
      "F1-score: 0.3459103156274057\n",
      "ROC AUC: 0.5050842849374659\n",
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO SIN STRATIFY EN Y\n",
      "Jaccard Index: 0.22045834874667514\n",
      "Exactitud: 0.3922734026745914\n",
      "Precisión: 0.5074037983874049\n",
      "Sensibilidad: 0.5224299606390368\n",
      "F1-score: 0.34083599746159465\n",
      "ROC AUC: 0.5224299606390368\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.22487618911889407\n",
      "Exactitud: 0.399702823179792\n",
      "Precisión: 0.50175983436853\n",
      "Sensibilidad: 0.5050842849374659\n",
      "F1-score: 0.3459103156274057\n",
      "ROC AUC: 0.5050842849374659\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.22045834874667514\n",
      "Exactitud: 0.3922734026745914\n",
      "Precisión: 0.5074037983874049\n",
      "Sensibilidad: 0.5224299606390368\n",
      "F1-score: 0.34083599746159465\n",
      "ROC AUC: 0.5224299606390368\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------')\n",
    "nearestCentroid(X,y,1,1)\n",
    "print('------------------------------------------------------------------')\n",
    "nearestCentroid(X,y,1,0)\n",
    "print('------------------------------------------------------------------')\n",
    "nearestCentroid(X,y,0,1)\n",
    "print('------------------------------------------------------------------')\n",
    "nearestCentroid(X,y,0,0)\n",
    "print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c386bb9-a262-4b6d-bfbc-2a67d714d95f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=df_no_nan.drop(['BAD','JOB','REASON'],axis=1)\n",
    "y=df_no_nan['BAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53a35695-7460-40e8-b92b-b3ad36e4ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.7088131993792371\n",
      "Exactitud: 0.9405646359583952\n",
      "Precisión: 0.8240142404116556\n",
      "Sensibilidad: 0.7944671016856988\n",
      "F1-score: 0.8083276372750057\n",
      "ROC AUC: 0.7944671016856988\n",
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO SIN STRATIFY EN Y\n",
      "Jaccard Index: 0.6428482972136222\n",
      "Exactitud: 0.9286775631500743\n",
      "Precisión: 0.7703522640593579\n",
      "Sensibilidad: 0.7256743459134058\n",
      "F1-score: 0.7454132778513335\n",
      "ROC AUC: 0.7256743459134058\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.7088131993792371\n",
      "Exactitud: 0.9405646359583952\n",
      "Precisión: 0.8240142404116556\n",
      "Sensibilidad: 0.7944671016856988\n",
      "F1-score: 0.8083276372750057\n",
      "ROC AUC: 0.7944671016856988\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO SIN STRATIFY EN Y\n",
      "Jaccard Index: 0.6568971009875757\n",
      "Exactitud: 0.9331352154531947\n",
      "Precisión: 0.7888181174805379\n",
      "Sensibilidad: 0.736223662884927\n",
      "F1-score: 0.7591554336156507\n",
      "ROC AUC: 0.7362236628849271\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------')\n",
    "ArbolDecision(X,y,1,1,4)\n",
    "print('------------------------------------------------------------------')\n",
    "ArbolDecision(X,y,1,0,4)\n",
    "print('------------------------------------------------------------------')\n",
    "ArbolDecision(X,y,0,1,4)\n",
    "print('------------------------------------------------------------------')\n",
    "ArbolDecision(X,y,0,0,4)\n",
    "print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d228874b-f3cb-4df0-a6d5-0847a6efcb48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=df_no_nan.drop(['BAD','JOB','REASON'],axis=1)\n",
    "y=df_no_nan['BAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd73aea3-4155-469f-9421-11cfe3ccaafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.7448257930317213\n",
      "Exactitud: 0.9583952451708767\n",
      "Precisión: 0.9781591263650546\n",
      "Sensibilidad: 0.7666666666666666\n",
      "F1-score: 0.8366618126343527\n",
      "ROC AUC: 0.7666666666666666\n",
      "------------------------------------------------------------------\n",
      "MODELO NORMALIZADO SIN STRATIFY EN Y\n",
      "Jaccard Index: 0.7379658385093169\n",
      "Exactitud: 0.9598811292719168\n",
      "Precisión: 0.9790372670807453\n",
      "Sensibilidad: 0.7589285714285714\n",
      "F1-score: 0.8304706815319308\n",
      "ROC AUC: 0.7589285714285714\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.7629890453834116\n",
      "Exactitud: 0.9613670133729569\n",
      "Precisión: 0.9796557120500782\n",
      "Sensibilidad: 0.7833333333333333\n",
      "F1-score: 0.8513187410781048\n",
      "ROC AUC: 0.7833333333333333\n",
      "------------------------------------------------------------------\n",
      "MODELO SIN NORMALIZADO CON STRATIFY EN Y\n",
      "Jaccard Index: 0.7573153093012907\n",
      "Exactitud: 0.962852897473997\n",
      "Precisión: 0.9805295950155763\n",
      "Sensibilidad: 0.7767857142857143\n",
      "F1-score: 0.846393324386258\n",
      "ROC AUC: 0.7767857142857143\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------')\n",
    "ArbolRandom(X,y,1,1)\n",
    "print('------------------------------------------------------------------')\n",
    "ArbolRandom(X,y,1,0)\n",
    "print('------------------------------------------------------------------')\n",
    "ArbolRandom(X,y,0,1)\n",
    "print('------------------------------------------------------------------')\n",
    "ArbolRandom(X,y,0,0)\n",
    "print('------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d7ec3-d04b-47db-a7f1-9b0efb89d42e",
   "metadata": {},
   "source": [
    "De momento el ganador es el RamdonForest pero vamos a hacer un bucle para foresDecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e0e569d-1cf7-4473-a2a2-56daf0116eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=ArbolDecision2(X,y,1,1,1)\n",
    "info_leaf=1\n",
    "b=0\n",
    "for i in range(1,1000):\n",
    "    \n",
    "\n",
    "    b=ArbolDecision2(X,y,1,1,i)\n",
    "    if b>a:\n",
    "        a=b\n",
    "        info_leaf=i\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    b=ArbolDecision2(X,y,1,0,i)\n",
    "    if b>a:\n",
    "        a=b\n",
    "        info_leaf=i\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    b=ArbolDecision2(X,y,0,1,i)\n",
    "    if b>a:\n",
    "        a=b\n",
    "        info_leaf=i\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    b=ArbolDecision2(X,y,0,0,i)\n",
    "    if b>a:\n",
    "        a=b\n",
    "        info_leaf=i\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffa9af79-2b57-4dc1-9a93-eee8443e122e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de leaf es: 7 el mayor f1 es: 0.8426300981346126\n"
     ]
    }
   ],
   "source": [
    "print(f'El numero de leaf es: {info_leaf} el mayor f1 es: {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747d1c7-e55c-4eb3-b015-beafdea6837d",
   "metadata": {},
   "source": [
    "´funcion para el bucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8c5e43a-45e0-460f-8d89-a5138239c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ArbolDecision2(X, y, normalizar, stratify, min_samples):\n",
    "    if normalizar and stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=min_samples)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        # print(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "        # print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"Exactitud:\", accuracy_score(y_test, yhat))\n",
    "        # print(\"Precisión:\", precision_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"Sensibilidad:\", recall_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"F1-score:\", f1_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        return f1_score(y_test, yhat, average=\"macro\")\n",
    "\n",
    "    elif normalizar and not stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=min_samples)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        # print(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "        # print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"Exactitud:\", accuracy_score(y_test, yhat))\n",
    "        # print(\"Precisión:\", precision_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"Sensibilidad:\", recall_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"F1-score:\", f1_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        return f1_score(y_test, yhat, average=\"macro\")\n",
    "\n",
    "    elif stratify and not normalizar:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=min_samples)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        # print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        # print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"Exactitud:\", accuracy_score(y_test, yhat))\n",
    "        # print(\"Precisión:\", precision_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"Sensibilidad:\", recall_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"F1-score:\", f1_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        return f1_score(y_test, yhat, average=\"macro\")\n",
    "\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "        model = DecisionTreeClassifier(min_samples_leaf=min_samples)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        # print(f'MODELO SIN NORMALIZADO SIN STRATIFY EN Y')\n",
    "        # print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"Exactitud:\", accuracy_score(y_test, yhat))\n",
    "        # print(\"Precisión:\", precision_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"Sensibilidad:\", recall_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"F1-score:\", f1_score(y_test, yhat, average=\"macro\"))\n",
    "        # print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        return f1_score(y_test, yhat, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b45507-5adf-4f84-94c5-756725cf28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ArbolRandom2(X,y,normalizar,stratify,i):\n",
    "    if(normalizar)and(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = RandomForestClassifier(max_depth=i)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        print(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "        print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "#         confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "     \n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "#         plt.xlabel('Predicción')\n",
    "#         plt.ylabel('Verdad');\n",
    "#         plt.title(f'MODELO NORMALIZADO CON STRATIFY EN Y')\n",
    "        return f1_score(y_test, yhat, average=\"macro\")\n",
    "    elif(normalizar)and not(stratify):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)#aplicamos el scaler a xtrain y con el scaler resultante transformamos xtrain y xtest\n",
    "        X_train_scaler = scaler.transform(X_train)\n",
    "        X_test_scaler = scaler.transform(X_test)\n",
    "        model = RandomForestClassifier(max_depth=i)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        # print(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "        # print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        # print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        # print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        # print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        # print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        # print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO NORMALIZADO SIN STRATIFY EN Y')\n",
    "        return f1_score(y_test, yhat, average=\"macro\")\n",
    "    elif(stratify)and not(normalizar):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42, stratify=y)\n",
    "        model = RandomForestClassifier(max_depth=i)\n",
    "        model.fit(X_train, y_train) \n",
    "        yhat = model.predict(X_test)\n",
    "        # print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        # print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "        # print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "        # print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "        # print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "        # print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "        # print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "        # confusion_matrix(y_test, yhat, labels = [0, 1])\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # sns.heatmap(confusion_matrix(y_test, yhat, labels = [0, 1]), annot=True, cmap='rainbow')\n",
    "        # plt.xlabel('Predicción')\n",
    "        # plt.ylabel('Verdad');\n",
    "        # plt.title(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "        return f1_score(y_test, yhat, average=\"macro\")\n",
    "    else:\n",
    "         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "         model = RandomForestClassifier(max_depth=i)\n",
    "         model.fit(X_train, y_train) \n",
    "         yhat = model.predict(X_test)\n",
    "         # print(f'MODELO SIN NORMALIZADO CON STRATIFY EN Y')\n",
    "         # print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "         # print(\"Exactitud:\"    , accuracy_score(y_test, yhat))\n",
    "         # print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "         # print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "         # print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "         # print(\"ROC AUC:\", roc_auc_score(y_test, yhat))\n",
    "         return f1_score(y_test, yhat, average=\"macro\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8a402-1c7f-4576-b070-81f68b936e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476821ee-118c-4858-97e4-394360256d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab46a33-d7c4-450f-b534-013d0eb02b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbcc0a-7269-49fa-b4af-52cecf5ea8db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862409c-8d6f-4963-a9a6-6e163cf45216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498b90a-f950-4126-9fab-4d14dbf78f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be44916-5e01-45b0-bad2-c82b6c1c4d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758286b9-f757-43f9-9d7a-08832a969cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7511d71e-7891-41e4-bf4e-902077ffe4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5600a85-7872-44ea-a7a2-b5aa27573b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a668121-1dec-4aad-bce5-ee7c98578529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51d101-a3ba-41b3-a4d0-37e0879b2141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
